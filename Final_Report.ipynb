{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D face reconstruction from low-resolution images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Angelo Garangau Menezes - NÂ°USP: 11413492"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Abstract:\n",
    "Since the introduction of models that could reconstruct the dense 3D geometry of a face from a single image, there has been a trend in academia for models that could enhance this capability in high-resolution scenarios. However, the reconstruction event is also important for situations where images in low-resolution are the majority, such as in general surveillance.\n",
    "Most of the software that present features related to 3D face reconstruction usually include 3D morphable model fitting which may be computationally expensive and often do not bring enough details, mainly when the image to be used in the first place is a low-resolution one.\n",
    "\n",
    "This project evaluated different resolution scenarios and explored a deep volumetric regression network to infer 3D depth maps directly of images of faces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 300 W-LP dataset was used for training the super-resolution CNN algorithm and the face reconstruction algoritm. The dataset contains 3837 images of faces and their volume mappings. It has been produced by fitting a 3D morphable model to unconstrained images of the 300W large pose dataset using a multi-feature fitting approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](report_images/image_samples.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A summary of the pipeline evaluated can be seen in the figure below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](report_images/3D-Face-Reconstruction.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1 - 32x32 -> 128x128x200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, all the images in the database were resized to 32x32 and 128x128 in order to create pairs for mapping low-resolution inputs to targets. The shape 128x128 was chosen because it was the shape of input images for the 3D reconstruction model.\n",
    "A small comparison between resolutions can be seen in the image below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](report_images/32-128_comparison.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the mapping to a higher resolution was obtained by using the following algorithms:\n",
    "\n",
    "- Bilinear Interpolation\n",
    "- Bicubic Interpolation\n",
    "- SubPixel CNN (Shi et al, 2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](report_images/sub-pixel-cnn.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The subpixel CNN was trained with the following parameters:\n",
    "- Batch size: 32\n",
    "- Number of epochs: 300\n",
    "- Loss: MSE\n",
    "- Optimizer: Adam\n",
    "- Learning Rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2 - 64x64 -> 128x128x200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the same idea of the first experiment, images were resized to a lower resolution and then up-scaled to check if the 3D reconstruction would work properly. However, due to time constraints, only bilinear and bicubic interpolation were applied.\n",
    "\n",
    "A small comparison of the difference between 64x64 and 128x128 can be seen below.\n",
    "\n",
    "![title](report_images/64-128_comparison.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D Face Reconstruction Algorithm Evaluated\n",
    "#### - Large Pose 3D Face Reconstruction from a Single Image via Direct Volumetric CNN Regression (Jackson et al, 2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](report_images/Hourglass-Net.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The volumetric regression network took as input an image of 128x128 and its output was a 128x128x200 depth map.\n",
    "The network architecture and parameters were extracted from their original paper. The settings were the following:\n",
    "- Batch size: 4\n",
    "- Number of epochs: 55\n",
    "- Loss: Cross-Entropy\n",
    "- Optimizer: RMSProp\n",
    "- Learning Rate: 0.001 with decay of 90% every 5 steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Up-Sampling 4x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original\n",
    "\n",
    "![title](report_images/orig-32.png)\n",
    "\n",
    "Bilinear Interpolation\n",
    "![title](report_images/lin-32-result.png)\n",
    "\n",
    "Bicubic Interpolation\n",
    "![title](report_images/cub-32-result.png)\n",
    "\n",
    "SubPixel CNN\n",
    "\n",
    "![title](report_images/cnn-32-result.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3D Depth maps for the third image\n",
    "\n",
    "![title](report_images/3D-shapes-32.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Up-Sampling 2x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bilinear Interpolation\n",
    "![title](report_images/lin-64-result.png)\n",
    "\n",
    "Bicubic Interpolation\n",
    "![title](report_images/cub-64-result.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3D Depth maps for the third image\n",
    "\n",
    "![title](report_images/3D-shapes-64.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As could be seen by the presented results, the accuracy of the reconstruction is highly correlated with the resolution of the image used as input. Also, it is noticeable that the CNN was not able to present accurate results despite being a more computationally expensive method for up-scaling an image. This might be related to the fact that there were not many examples for the model to generalize good pixel approximations to the original images. In order to obtain better results, other more sophisticated architectures can be explored as well as different data augmentation techniques.\n",
    "\n",
    "It is worth mentioning that the direct volumetric regression network took around 70 minutes to train only one epoch in an Intel i7-6500U with GeForce GTX 950M (4GB). This made the hyperparameter tuning and the search for different architectures a massively time-consuming task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Considerations\n",
    "\n",
    "It could be checked that when the images were from resolutions up to 32x32, the reconstruction did not present accurate high frequency componentes for most of the cases since there were not enough details to produce good looking 128x128 images. Consequently, the deep network responsible for the regression of the mesh could not generate good approximations as well. However, when the images were from 64x64 and the needed upscaling was only up to 2x, the up-sampling algorithms performed better as it could be checked by their PSNR and SSIM. In this last case, the 3D depth estimation algorithm was successful in recovering fine details such nose and forehead shapes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "- Jackson, Aaron S., et al. \"Large pose 3D face reconstruction from a single image via direct volumetric CNN regression.\" Proceedings of the IEEE International Conference on Computer Vision. 2017.\n",
    "- Shi, Wenzhe, et al. \"Real-time single image and video super-resolution using an efficient sub-pixel convolutional neural network.\" Proceedings of the IEEE conference on computer vision and pattern recognition. 2016."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Image Class Kernel",
   "language": "python",
   "name": "image_class"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
