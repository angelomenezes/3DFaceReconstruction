{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D face reconstruction from low-resolution images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Angelo Garangau Menezes - NÂ°USP: 11413492"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Abstract:\n",
    "Since the introduction of models that could reconstruct the dense 3D geometry of a face from a single image, there has been a trend in academia for models that could enhance this capability in high-resolution scenarios. However, the reconstruction event is also important for situations where images in low-resolution are the majority, such as in general surveillance.\n",
    "Most of the software that present features related to 3D face reconstruction usually include 3D morphable model fitting which may be computationally expensive and often do not bring enough details, mainly when the image to be used in the first place is a low-resolution one.\n",
    "\n",
    "This project evaluated different resolution scenarios and explored a deep volumetric regression network to infer 3D depth maps directly of images of faces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Motivation\n",
    "\n",
    "![title](report_images/motivation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 300 W-LP dataset was used for training the super-resolution CNN algorithm and the face reconstruction algoritm. The dataset contains 3837 images of faces and their volume mappings. It has been produced by fitting a 3D morphable model to unconstrained images of the 300W large pose dataset using a multi-feature fitting approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](report_images/image_samples.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A summary of the pipeline evaluated can be seen in the figure below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](report_images/3D-Face-Reconstruction.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1 - 32x32 -> 128x128x200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, all the images in the database were resized to 32x32 and 128x128 in order to create pairs for mapping low-resolution inputs to targets. The shape 128x128 was chosen because it was the shape of input images for the 3D reconstruction model.\n",
    "A small comparison between resolutions can be seen in the image below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](report_images/32-128_comparison.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the mapping to a higher resolution was obtained by using the following algorithms:\n",
    "\n",
    "- Bilinear Interpolation\n",
    "- Bicubic Interpolation\n",
    "- SubPixel CNN (Shi et al, 2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](report_images/sub-pixel-cnn.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The subpixel CNN for this experiment was trained with the following parameters:\n",
    "- Batch size: 32\n",
    "- Number of epochs: 300\n",
    "- Loss: MSE\n",
    "- Optimizer: Adam\n",
    "- Learning Rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2 - 64x64 -> 128x128x200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the same idea of the first experiment, images were resized to a lower resolution and then up-scaled to check if the 3D reconstruction would work properly.\n",
    "A small comparison of the difference between 64x64 and 128x128 can be seen below.\n",
    "\n",
    "![title](report_images/64-128_comparison.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this experiment, the subpixel CNN was trained with the following parameters:\n",
    "- Batch size: 64\n",
    "- Number of epochs: 500\n",
    "- Loss: MSE\n",
    "- Optimizer: Adam\n",
    "- Learning Rate = 0.01 with decay to 10% every 100 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D Face Reconstruction Algorithm Evaluated\n",
    "#### - Large Pose 3D Face Reconstruction from a Single Image via Direct Volumetric CNN Regression (Jackson et al, 2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](report_images/Hourglass-Net.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The volumetric regression network took as input an image of 128x128 and its output was a 128x128x200 depth map.\n",
    "The network architecture and parameters were extracted from their original paper. The settings were the following:\n",
    "- Batch size: 4\n",
    "- Number of epochs: 55\n",
    "- Loss: Cross-Entropy\n",
    "- Optimizer: RMSProp\n",
    "- Learning Rate: 0.001 with decay of 90% every 5 steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Criteria\n",
    "##### Super-Resolution\n",
    "- PSNR (Peak Signal-to-Noise Ratio)\n",
    "$= 10\\log_{10}(\\frac{S^{2}}{MSE})$\n",
    "\n",
    "A metric obtained by the ratio between the maximum possible power of a signal and the power of corrupting noise that affects the fidelity of its representation.\n",
    "\n",
    "\n",
    "\n",
    "- SSIM (Structural Similarity)\n",
    "$= \\frac{(2 \\mu_{x} \\mu_{y} + c_{1})(2\\sigma_{xy} + c_{2})}{(\\mu_{x}^2 + \\mu_{y}^2 + c_{1})(\\sigma_{x}^2 + \\sigma_{y}^2 + c_{2})}$\n",
    "\n",
    "A perceptual metric that quantifies image quality degradation based on the measurement of the perceptual difference between two similar images.\n",
    "\n",
    "Face Reconstruction\n",
    "- NME (Normalised Mean Error)$=\\frac{1}{N}\\sum_{k=1}^{N}\\frac{\\left \\| x_{k} - y_{k} \\right \\| _{2}}{d}$\n",
    "\n",
    "Average per vertex of the Euclidean distance between the estimated and ground truth reconstruction normalised by the outer 3D interocular distance\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Up-Sampling 4x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original 32x32\n",
    "\n",
    "![title](report_images/orig-32.png)\n",
    "\n",
    "Bilinear Interpolation\n",
    "\n",
    "![title](report_images/lin-32-result.png)\n",
    "\n",
    "Bicubic Interpolation\n",
    "\n",
    "![title](report_images/cub-32-result.png)\n",
    "\n",
    "SubPixel CNN\n",
    "\n",
    "![title](report_images/cnn-32-result.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|PSNR/SSIM| Img1 | Img2 | Img3 | Img4 | Img5 |\n",
    "|----------|----------|----------|----------|----------|----------|\n",
    "| Bilinear |25.086 / 0.755|23.402 / 0.740|24.437 / 0.700|24.838 / 0.720|18.353 / 0.607|\n",
    "| Bicubic  |24.673 / 0.747|24.673 / 0.747|23.999 / 0.696|24.574 / 0.722|17.603 / 0.602|\n",
    "| CNN      |23.972 / 0.737|22.225 / 0.688|22.811 / 0.661|23.301 / 0.699|16.291 / 0.559|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3D Depth maps for the third image\n",
    "\n",
    "![title](report_images/3D-shapes-32_.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Up-Sampling 2x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original 64x64\n",
    "\n",
    "![title](report_images/orig-64.png)\n",
    "\n",
    "Bilinear Interpolation\n",
    "\n",
    "![title](report_images/lin-64-result.png)\n",
    "\n",
    "Bicubic Interpolation\n",
    "\n",
    "![title](report_images/cub-64-result.png)\n",
    "\n",
    "SubPixel CNN\n",
    "\n",
    "![title](report_images/cnn-64-result.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|PSNR/SSIM| Img1 | Img2 | Img3 | Img4 | Img5 |\n",
    "|----------|----------|----------|----------|----------|----------|\n",
    "| Bilinear |29.693 / 0.896|27.891 / 0.894|29.232 / 0.883|29.501 / 0.903|21.755 / 0.817|\n",
    "| Bicubic  |29.374 / 0.894|27.466 / 0.886|29.020 / 0.888|29.361 / 0.910|20.965 / 0.817|\n",
    "| CNN      |28.619 / 0.883|25.789 / 0.865|28.039 / 0.873|28.302 / 0.896|20.028 / 0.795|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3D Depth maps for the third image\n",
    "\n",
    "![title](report_images/3D-shapes-64.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As could be seen by the presented results, the accuracy of the reconstruction is highly dependent on the resolution of the image used as input. Also, it is noticeable that the CNN was not able to present accurate results despite being a more computationally expensive method for up-scaling an image. This might be related to the fact that there were not many examples for the model to generalize good pixel approximations to the original images. In order to obtain better results, other more sophisticated architectures can be explored as well as different data augmentation techniques.\n",
    "\n",
    "The face reconstruction algorithm was able to reconstruct even when faces were occluded. This property was stated initially by the authors as one of its pros; however, it failed some of the reconstructions where there was shadow and darker tons of skins in the image. This situation happened mainly because, in low-resolution, the difference in pixel intensity between background and the face is not discriminating enough, and after super-resolving the image, the reconstruction model had trouble to differentiate both sectors.\n",
    "\n",
    "It is worth mentioning that the direct volumetric regression network took around 70 minutes to train only one epoch in an Intel i7-6500U with GeForce GTX 950M (4GB). This made the hyperparameter tuning and the search for different architectures a massively time-consuming task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Considerations\n",
    "\n",
    "It could be checked that when the images were from resolutions up to 32x32, the reconstruction did not present accurate high frequency componentes for most of the cases since there were not enough details to produce good looking 128x128 images. Consequently, the deep network responsible for the regression of the mesh could not generate good approximations as well. However, when the images were from 64x64 and the needed upscaling was only up to 2x, the up-sampling algorithms performed better as it could be checked by their PSNR and SSIM. In this last case, the 3D depth estimation algorithm was successful in recovering fine details for the facial shape and pose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "- Jackson, Aaron S., et al. \"Large pose 3D face reconstruction from a single image via direct volumetric CNN regression.\" Proceedings of the IEEE International Conference on Computer Vision. 2017.\n",
    "- Shi, Wenzhe, et al. \"Real-time single image and video super-resolution using an efficient sub-pixel convolutional neural network.\" Proceedings of the IEEE conference on computer vision and pattern recognition. 2016.\n",
    "- Winkler, Rouven, et al. \"3D Face Reconstruction from Low-Resolution Images with Convolutional Neural Networks.\" Proceedings of the 2018 the 2nd International Conference on Video and Image Processing. ACM, 2018."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Image Class Kernel",
   "language": "python",
   "name": "image_class"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
